# Optical Flow & Hand Tracking Benchmark

This project explores **hand tracking in video** and **optical flow estimation** using both classical computer vision algorithms and deep learning models.  
Developed as part of the **Image, Audio and Video Processing (PIAV)** course, it benchmarks 5 approaches on the same data and provides a comparative analysis of **position** and **velocity**.


## üéØ Objectives
- Track the **right hand** in the `people2` video using different algorithms.  
- Compare **position stability** and **velocity estimates** across methods.  
- Apply the same algorithms to the **FlyingChairs dataset** and evaluate against ground truth.


## üß© Methods implemented
- **YOLOv8-Pose** ‚Üí detects people and tracks keypoint 10 (right hand).  
- **Lucas‚ÄìKanade (manual implementation)** ‚Üí optical flow from first principles (Sobel gradients, normal equations).  
- **Lucas‚ÄìKanade (OpenCV)** ‚Üí efficient sparse tracking with pyramids.  
- **Farneb√§ck** ‚Üí dense optical flow, sampled at the keypoint.  
- **RAFT** ‚Üí state-of-the-art deep learning optical flow model (torchvision pretrained).  

Velocity is computed as **Euclidean displacement √ó FPS**, allowing fair comparison across methods.


## üìä Results at a glance
- **YOLOv8-Pose**: stable positions, higher and more dynamic velocity estimates.  
- **RAFT / Farneb√§ck / LK OpenCV**: consistent trajectories with moderate velocity fluctuations.  
- **LK Manual**: noticeable deviations, highlighting precision limitations of the hand-coded approach.  

On **FlyingChairs**, RAFT achieves results closest to the ground truth, with Farneb√§ck and LK producing reasonable but less precise flow fields.


## üõ†Ô∏è Tech stack
- **Python**  
- **PyTorch** + **torchvision (RAFT)**  
- **Ultralytics YOLOv8-Pose**  
- **OpenCV** (Lucas‚ÄìKanade, Farneb√§ck, video I/O)  
- **NumPy, Matplotlib**  
- **Google Colab** (GPU execution)


## üöÄ How to use
1. Clone this repository:
   ```bash
   git clone https://github.com/alebola/optical-flow-tracking-benchmark.git
   cd optical-flow-tracking-benchmark
   ```
2. Install dependencies:
   ```bash
   pip install ultralytics opencv-python torch torchvision matplotlib numpy
   ```
3. Open and run the notebook:
   ```bash
   notebooks/optical_flow_tracking.ipynb
   ```
4. Required inputs:
   - videos/people2.mp4
   - A sample from the FlyingChairs dataset (00005_img1.ppm, 00005_img2.ppm, 00005_flow.flo)


## üìù Notes
- This repository only includes a small sample of FlyingChairs (5 pairs). The full dataset (22,872 pairs) can be downloaded from the official source [FlyingChairs dataset](https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html). 
- This project was developed jointly with [David Garc√≠a D√≠az](https://github.com/Davidgrcdz) as part of the **Image, Audio and Video Processing (PIAV)** course.


